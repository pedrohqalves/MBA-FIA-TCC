{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install geopy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ===============================\n",
    "\n",
    "\n",
    "# 1 . Importando as bibliotecas básicas\n",
    "\n",
    "\n",
    "# ==============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ==============================\n",
    "\n",
    "\n",
    "# 2. Lendo as bases de dados\n",
    "\n",
    "\n",
    "# =============================="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeiro lendo as bases de Clima\n",
    "\n",
    "### No caso destas bases, temos o nome da estação, que pode ou não ser o mesmo nome da cidade que ela está localizada. Para facilitar posteriormente cruzarmos cidade a cidade com os casos de dengue, vamos usar os dados de latitude e longitude para descobrir a cidade onde está localizada a estação\n",
    "\n",
    "### Vamos acrescentar uma coluna em cada base de cada estação mostrando cidade, estado e cep (que pode facilitar depois a localização também)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ----------------------------------------------\n",
    "\n",
    "\n",
    "### Para cada base vamos ler o cabeçalho, retirar os dados de localização, acrescentar como colunas na base, e guardar os dados para serem empilhados com os da próxima base, e assim por diante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro pegando uma lista com todos os arquivos na pasta onde estão os dados\n",
    "\n",
    "dadosclima = []\n",
    "\n",
    "import sys\n",
    "\n",
    "root = r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima\\Bases Anuais'\n",
    "      \n",
    "            \n",
    "for root, dirs, files in os.walk(root):\n",
    "     for file in files:\n",
    "        dadosclima.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Como a base de dados ficou muito grande, este comando e o seguinte devem ser rodados separadamente\n",
    "# com limpeza de memória entre eles\n",
    "\n",
    "#Importa a lib para descobrir localização através de coordenadas\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='teste_dengue')\n",
    "\n",
    "clima = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in dadosclima:\n",
    "    if dadosclima.index(i) < 1000:\n",
    "        \n",
    "        \n",
    "        \n",
    "        print('Faltam ' + str(len(dadosclima) - dadosclima.index(i) +1) +' itens na lista' )\n",
    "        print('Inicio Item ' + str(dadosclima.index(i)))\n",
    "        inicio = time.time()\n",
    "        base1 = pd.read_csv(i, delimiter = ';',engine = 'python', nrows = 3)\n",
    "        base2 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 3, nrows = 4)\n",
    "        estado = base1.iloc[0,1]\n",
    "        estacao = base1.iloc[1,1]\n",
    "        lat = str(base2.iloc[0,1]).replace(',','.')\n",
    "        long = str(base2.iloc[1,1]).replace(',','.')\n",
    "        \n",
    "        # Tratando casos onde temos latitude que começa apenas com . ou , (positivos e negativos)\n",
    "        \n",
    "        if lat[0] == '.':\n",
    "            lat = str(0)+lat\n",
    "        elif lat[0] == '-':\n",
    "            lat = '-' + str(0) + lat[1:]\n",
    "        else:\n",
    "            pass\n",
    "        if long[0] == '.':\n",
    "            long = str(0)+long\n",
    "        elif long[0] == '-':\n",
    "            long = '-'+ str(0) + long [1:]                \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        # Passa as coordenadas \n",
    "        \n",
    "        location = geolocator.reverse(lat +', ' + long)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            cidade = location.raw['address']['city'] \n",
    "\n",
    "        except:\n",
    "            cidade = 'Erro'\n",
    "            \n",
    "        try:\n",
    "            cep = location.raw['address']['postcode'] \n",
    "        except:\n",
    "            cep = 'Erro'\n",
    "        \n",
    "        # Pega o restante da base, e adiciona colunas com os valores que descobrimos anteriormente\n",
    "        \n",
    "        base3 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 8)\n",
    "        base3['estacao'] = estacao\n",
    "        base3['estado'] = estado\n",
    "        base3['cidade'] = pd.Series()\n",
    "        base3['cep'] = pd.Series()\n",
    "        base3['lat'] = lat\n",
    "        base3['long'] = long\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            base3['cidade'] = cidade\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            base3['cep'] = cep\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        clima = clima.append(base3)\n",
    "        fim = time.time()\n",
    "        tempo = fim - inicio\n",
    "\n",
    "        print('Fim Item ' + str(dadosclima.index(i)))\n",
    "        print('Duração : ' + str(tempo) + ' segundos')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "\n",
    "\n",
    "clima.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part1.csv')\n",
    "del clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como a base de dados ficou muito grande, este comando e o seguinte devem ser rodados separadamente\n",
    "# com limpeza de memória entre eles\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='teste_dengue')\n",
    "\n",
    "clima = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in dadosclima:\n",
    "    if 1000 <= dadosclima.index(i) < 2000:\n",
    "        \n",
    " \n",
    "        \n",
    "        print('Faltam ' + str(len(dadosclima) - dadosclima.index(i) +1) +' itens na lista' )\n",
    "        print('Inicio Item ' + str(dadosclima.index(i)))\n",
    "        inicio = time.time()\n",
    "        base1 = pd.read_csv(i, delimiter = ';',engine = 'python', nrows = 3)\n",
    "        base2 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 3, nrows = 4)\n",
    "        estado = base1.iloc[0,1]\n",
    "        estacao = base1.iloc[1,1]\n",
    "        lat = str(base2.iloc[0,1]).replace(',','.')\n",
    "        long = str(base2.iloc[1,1]).replace(',','.')\n",
    "        \n",
    "        # Tratando casos onde temos latitude que começa apenas com . ou , (positivos e negativos)\n",
    "        \n",
    "        if lat[0] == '.':\n",
    "            lat = str(0)+lat\n",
    "        elif lat[0] == '-':\n",
    "            lat = '-' + str(0) + lat[1:]\n",
    "        else:\n",
    "            pass\n",
    "        if long[0] == '.':\n",
    "            long = str(0)+long\n",
    "        elif long[0] == '-':\n",
    "            long = '-'+ str(0) + long [1:]                \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        # Passa as coordenadas \n",
    "        \n",
    "        location = geolocator.reverse(lat +', ' + long)\n",
    "        \n",
    "         \n",
    "        try:\n",
    "            cidade = location.raw['address']['city'] \n",
    "\n",
    "        except:\n",
    "            cidade = 'Erro'\n",
    "            \n",
    "        try:\n",
    "            cep = location.raw['address']['postcode'] \n",
    "        except:\n",
    "            cep = 'Erro'\n",
    "        \n",
    "        \n",
    "        # Pega o restante da base, e adiciona colunas com os valores que descobrimos anteriormente\n",
    "        \n",
    "        base3 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 8)\n",
    "        base3['estacao'] = estacao\n",
    "        base3['estado'] = estado\n",
    "        base3['cidade'] = pd.Series()\n",
    "        base3['cep'] = pd.Series()\n",
    "        base3['lat'] = lat\n",
    "        base3['long'] = long\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            base3['cidade'] = cidade\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            base3['cep'] = cep\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        clima = clima.append(base3)\n",
    "        fim = time.time()\n",
    "        tempo = fim - inicio\n",
    "\n",
    "        print('Fim Item ' + str(dadosclima.index(i)))\n",
    "        print('Duração : ' + str(tempo) + ' segundos')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "clima.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part2.csv')\n",
    "del clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como a base de dados ficou muito grande, este comando e o seguinte devem ser rodados separadamente\n",
    "# com limpeza de memória entre eles\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='teste_dengue')\n",
    "\n",
    "clima = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in dadosclima:\n",
    "    if 2000 <=dadosclima.index(i) < 3000:\n",
    "        \n",
    " \n",
    "        \n",
    "        print('Faltam ' + str(len(dadosclima) - dadosclima.index(i) +1) +' itens na lista' )\n",
    "        print('Inicio Item ' + str(dadosclima.index(i)))\n",
    "        inicio = time.time()\n",
    "        base1 = pd.read_csv(i, delimiter = ';',engine = 'python', nrows = 3)\n",
    "        base2 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 3, nrows = 4)\n",
    "        estado = base1.iloc[0,1]\n",
    "        estacao = base1.iloc[1,1]\n",
    "        lat = str(base2.iloc[0,1]).replace(',','.')\n",
    "        long = str(base2.iloc[1,1]).replace(',','.')\n",
    "        \n",
    "        # Tratando casos onde temos latitude que começa apenas com . ou , (positivos e negativos)\n",
    "        \n",
    "        if lat[0] == '.':\n",
    "            lat = str(0)+lat\n",
    "        elif lat[0] == '-':\n",
    "            lat = '-' + str(0) + lat[1:]\n",
    "        else:\n",
    "            pass\n",
    "        if long[0] == '.':\n",
    "            long = str(0)+long\n",
    "        elif long[0] == '-':\n",
    "            long = '-'+ str(0) + long [1:]                \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        # Passa as coordenadas \n",
    "        \n",
    "        location = geolocator.reverse(lat +', ' + long)\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            cidade = location.raw['address']['city'] \n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        try:\n",
    "            cep = location.raw['address']['postcode'] \n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Pega o restante da base, e adiciona colunas com os valores que descobrimos anteriormente\n",
    "        \n",
    "        base3 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 8)\n",
    "        base3['estacao'] = estacao\n",
    "        base3['estado'] = estado\n",
    "        base3['cidade'] = pd.Series()\n",
    "        base3['cep'] = pd.Series()\n",
    "        base3['lat'] = lat\n",
    "        base3['long'] = long\n",
    "        \n",
    "        \n",
    "          \n",
    "        try:\n",
    "            cidade = location.raw['address']['city'] \n",
    "\n",
    "        except:\n",
    "            cidade = 'Erro'\n",
    "            \n",
    "        try:\n",
    "            cep = location.raw['address']['postcode'] \n",
    "        except:\n",
    "            cep = 'Erro'\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        clima = clima.append(base3)\n",
    "        fim = time.time()\n",
    "        tempo = fim - inicio\n",
    "\n",
    "        print('Fim Item ' + str(dadosclima.index(i)))\n",
    "        print('Duração : ' + str(tempo) + ' segundos')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "    \n",
    "clima.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part3.csv')\n",
    "del clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como a base de dados ficou muito grande, este comando e o seguinte devem ser rodados separadamente\n",
    "# com limpeza de memória entre eles\n",
    "\n",
    "from geopy.geocoders import Nominatim\n",
    "geolocator = Nominatim(user_agent='teste_dengue')\n",
    "\n",
    "clima = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in dadosclima:\n",
    "    if dadosclima.index(i) >= 3000:\n",
    "        \n",
    " \n",
    "        \n",
    "        print('Faltam ' + str(len(dadosclima) - dadosclima.index(i) +1) +' itens na lista' )\n",
    "        print('Inicio Item ' + str(dadosclima.index(i)))\n",
    "        inicio = time.time()\n",
    "        base1 = pd.read_csv(i, delimiter = ';',engine = 'python', nrows = 3)\n",
    "        base2 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 3, nrows = 4)\n",
    "        estado = base1.iloc[0,1]\n",
    "        estacao = base1.iloc[1,1]\n",
    "        lat = str(base2.iloc[0,1]).replace(',','.')\n",
    "        long = str(base2.iloc[1,1]).replace(',','.')\n",
    "        \n",
    "        # Tratando casos onde temos latitude que começa apenas com . ou , (positivos e negativos)\n",
    "        \n",
    "        if lat[0] == '.':\n",
    "            lat = str(0)+lat\n",
    "        elif lat[0] == '-':\n",
    "            lat = '-' + str(0) + lat[1:]\n",
    "        else:\n",
    "            pass\n",
    "        if long[0] == '.':\n",
    "            long = str(0)+long\n",
    "        elif long[0] == '-':\n",
    "            long = '-'+ str(0) + long [1:]                \n",
    "        else: \n",
    "            pass\n",
    "        \n",
    "        # Passa as coordenadas \n",
    "        \n",
    "        location = geolocator.reverse(lat +', ' + long)\n",
    "        \n",
    "        \n",
    "         \n",
    "        try:\n",
    "            cidade = location.raw['address']['city'] \n",
    "\n",
    "        except:\n",
    "            cidade = 'Erro'\n",
    "            \n",
    "        try:\n",
    "            cep = location.raw['address']['postcode'] \n",
    "        except:\n",
    "            cep = 'Erro'\n",
    "        \n",
    "        \n",
    "        # Pega o restante da base, e adiciona colunas com os valores que descobrimos anteriormente\n",
    "        \n",
    "        base3 = pd.read_csv(i, delimiter = ';',engine = 'python', skiprows = 8)\n",
    "        base3['estacao'] = estacao\n",
    "        base3['estado'] = estado\n",
    "        base3['cidade'] = pd.Series()\n",
    "        base3['cep'] = pd.Series()\n",
    "        base3['lat'] = lat\n",
    "        base3['long'] = long\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            base3['cidade'] = cidade\n",
    "\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        try:\n",
    "            base3['cep'] = cep\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        \n",
    "        \n",
    "        clima = clima.append(base3)\n",
    "        fim = time.time()\n",
    "        tempo = fim - inicio\n",
    "\n",
    "        print('Fim Item ' + str(dadosclima.index(i)))\n",
    "        print('Duração : ' + str(tempo) + ' segundos')\n",
    "        \n",
    "\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "clima.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part4.csv')\n",
    "del clima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando agora a base de casos de dengue\n",
    "### Vamos seguir a estratégia: Com os dados de Dengue, tentar cruzar os dados com as bases de clima individualmente, para evitar de termos que consolidar uma base completa de clima que ficaria muito grande em memória.\n",
    "\n",
    "### As cidades e Estados onde não conseguirmos dados de dengue x clima, iremos retirar da análise e assim faremos o filtro para tentar reduzir um pouco os dados possibilitando uso da memória para consolidar uma abt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Primeiro pegando uma lista com todos os arquivos na pasta onde estão os dados\n",
    "\n",
    "dadosdengue = []\n",
    "\n",
    "import sys\n",
    "\n",
    "root = r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue\\DadosAnuaisCSV'\n",
    "      \n",
    "            \n",
    "for root, dirs, files in os.walk(root):\n",
    "     for file in files:\n",
    "        dadosdengue.append(os.path.join(root, file))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Casos de Dengue\n",
    "\n",
    "#Criando um DataFrame\n",
    "\n",
    "dengue = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in dadosdengue:\n",
    "    print(i)\n",
    "    inicio = time.time()\n",
    "    base1 = pd.read_csv(i, engine = 'python')\n",
    "    dengue = dengue.append(base1, sort = False)\n",
    "    fim = time.time()\n",
    "    duracao = fim - inicio\n",
    "    print(duracao)\n",
    "    \n",
    "dengue.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue//dengue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\quadr\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3020: DtypeWarning: Columns (2,9,13,23,24,46,47,48,52,54,56,58,64,66,70,76,87,103,117) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "dengue = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue//dengue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notific_dengue = dengue[['DT_NOTIFIC','ID_MUNICIP','NU_ANO','NU_NOTIFIC']].groupby(['DT_NOTIFIC','NU_ANO','ID_MUNICIP']).agg('count').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos usar o campo ID_MUNICIP posteriormente para fazer um join e descobrir o nome da cidade.\n",
    "# Vamos transformar o campo em string para não termos problemas no join\n",
    "\n",
    "notific_dengue['ID_MUNICIP'] = notific_dengue.ID_MUNICIP.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "notific_dengue.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue//notific_dengue.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "del dengue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lendo agora a base de cidades\n",
    "### Usaremos a base de cidades para identificar as cidades onde tivemos casos de dengue, para depois cruzar através da cidade os casos com os dados de clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cidades = pd.read_excel(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Cidades//RELATORIO_DTB_BRASIL_DISTRITO.xls')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Em uma das bases temos o código do município com 7 dígitos e em outra com 6, vamos igualar\n",
    "\n",
    "cidades['ID_MUNICIP'] = cidades['Código Município Completo'].apply(lambda x: str(x)[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_cidades = pd.merge(notific_dengue,cidades,how='inner',on='ID_MUNICIP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deletando as bases anteriores para liberar memória\n",
    "\n",
    "del cidades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_cidades.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue//denguecidades.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------\n",
    "\n",
    "# 3 . Tratando a base inicial de dados\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Temos todas as bases de dados que precisamos agora. Precisamos agregar e fazer join para começar a atacar o problema.\n",
    "\n",
    "### Temos a base de clima com dados de hora em hora de todas as estações de medição espalhadas pelo Brasil\n",
    "### Temos a base de número de notificações de dengue em cada cidade\n",
    "\n",
    "### Para cruzar estas duas bases a chave será o nome da cidade e data\n",
    "\n",
    "### A estratégia será verificar quantos cruzamentos temos de dados de clima x dengue para começar a análise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_cidades = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Casos Dengue//denguecidades.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dengue_cidades = dengue_cidades[['DT_NOTIFIC','ID_MUNICIP','NU_ANO','Nome_UF','Nome_Município','NU_NOTIFIC']]\n",
    "dengue_cidades = dengue_cidades.drop_duplicates(subset = ['DT_NOTIFIC','ID_MUNICIP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Começando com as bases de clima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Tratando os dados das bases.\n",
    "# Começando pelo clima 1\n",
    "\n",
    "clima1 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Como temos colunas com tipos diferentes de dados, vamos detectar o que está com tipos diferentes para poder tratar\n",
    "\n",
    "for i in clima1.columns:\n",
    "    print(clima1[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Temos muitos dados sendo lidos como string, provavelmente por conta da virgula em campos numericos. \n",
    "# Vamos começar ajustando esse ponto\n",
    "# Esta parte vai transformar colunas que são inteiras string para valores numéricos\n",
    "\n",
    "\n",
    "\n",
    "for i in clima1.iloc[:,3:20].columns:\n",
    "    \n",
    "    \n",
    "    print(i)\n",
    "    clima1[i] = [float(x.replace(',','.')) if isinstance(x, str) else float(x) for x in clima1[i]]\n",
    "\n",
    "    \n",
    "# cidade e cep precisamos transformar para string\n",
    "\n",
    "clima1.cidade = clima1.cidade.apply(lambda x: str(x))\n",
    "clima1.cep = clima1.cep.apply(lambda x: str(x))\n",
    "\n",
    "\n",
    "# for i in clima1.iloc[:,3:20].columns:\n",
    "#     print(i)\n",
    "#     print(type(clima1[i][0]))\n",
    "#     if isinstance(clima1[i][0], str) == True:        \n",
    "#         clima1[i] = clima1[i].apply(lambda x: float(x.replace(',','.')))\n",
    "#         print(type(clima1[i][0]))\n",
    "#     else: \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Vamos verificar se o tratamento foi efetivo\n",
    "\n",
    "for i in clima1.columns:\n",
    "    print(clima1[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora que todos os valores estão devidamente tratados, vamos reduzir a base para facilitar o trabalho em memória\n",
    "# Vamos reduzir a base a valores diários e não mais horários.\n",
    "\n",
    "# Como o efeito da dengue será visto em dias, não há necessidade a princípio de termos dados de clima de hora em hora\n",
    "# A tentativa será feita em cima de médias diárias\n",
    "\n",
    "\n",
    "clima1_reduzida = clima1.groupby(['DATA (YYYY-MM-DD)','estado','cidade','cep','lat','long']).agg('mean').reset_index()\n",
    "abt1 = pd.merge(clima1_reduzida,dengue_cidades, how = 'inner', left_on = ['DATA (YYYY-MM-DD)','cidade'], right_on = ['DT_NOTIFIC','Nome_Município'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt1.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clima1\n",
    "del clima1_reduzida\n",
    "del abt1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vamos executar a mesma estratégia para as bases de clima 2, 3 e 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clima 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando a base clima 2\n",
    "\n",
    "clima2 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Como temos colunas com tipos diferentes de dados, vamos detectar o que está com tipos diferentes para poder tratar\n",
    "\n",
    "for i in clima2.columns:\n",
    "    print(clima2[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in clima2.iloc[:,3:20].columns:\n",
    "    \n",
    "    \n",
    "    print(i)\n",
    "    clima2[i] = [float(x.replace(',','.')) if isinstance(x, str) else float(x) for x in clima2[i]]\n",
    "    \n",
    "    \n",
    "    \n",
    "#     print(i)\n",
    "#     print(type(clima2[i][0]))\n",
    "#     if isinstance(clima2[i][0], str) == True:        \n",
    "#         clima2[i] = clima2[i].apply(lambda x: float(x.replace(',','.')))\n",
    "#         print(type(clima2[i][0]))\n",
    "#     else: \n",
    "#         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cidade e cep precisamos transformar para string\n",
    "\n",
    "clima2.cidade = clima2.cidade.apply(lambda x: str(x))\n",
    "clima2.cep = clima2.cep.apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chegando se o tratamento foi efetivo\n",
    "\n",
    "for i in clima2.columns:\n",
    "    print(clima2[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora que todos os valores estão devidamente tratados, vamos reduzir a base para facilitar o trabalho em memória\n",
    "# Vamos reduzir a base a valores diários e não mais horários.\n",
    "\n",
    "# Como o efeito da dengue será visto em dias, não há necessidade a princípio de termos dados de clima de hora em hora\n",
    "# A tentativa será feita em cima de médias diárias\n",
    "\n",
    "\n",
    "clima2_reduzida = clima2.groupby(['DATA (YYYY-MM-DD)','estado','cidade','cep','lat','long']).agg('mean').reset_index()\n",
    "abt2 = pd.merge(clima2_reduzida,dengue_cidades, how = 'inner', left_on = ['DATA (YYYY-MM-DD)','cidade'], right_on = ['DT_NOTIFIC','Nome_Município'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt2.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clima2\n",
    "del clima2_reduzida\n",
    "del abt2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clima 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora para a base clima 3\n",
    "# A partir da base clima 3, o INMET adiciona uma outra coluna de data diferente. No meio da base temos essa mudança no schema\n",
    "# Teremos que tratar isso transformando tudo em uma coluna unica de data \n",
    "\n",
    "clima3 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clima3.Data = clima3.Data.apply(lambda x: str(x))\n",
    "\n",
    "clima3_part1 = clima3[clima3['DATA (YYYY-MM-DD)'].notnull()]\n",
    "clima3_part2 = clima3[clima3['DATA (YYYY-MM-DD)'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando a coluna de Data\n",
    "\n",
    "def ajuste_data(x : str):    \n",
    "    return(x[:4]+'-'+x[5:7]+'-'+x[8:10])\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "    \n",
    "clima3_part2['DATA (YYYY-MM-DD)'] = clima3_part2.Data.apply(lambda x: ajuste_data(x))\n",
    "\n",
    "clima3 = pd.concat([clima3_part1,clima3_part2], sort= False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clima3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clima3 = clima3.drop('Data', axis = 1)\n",
    "clima3 = clima3.drop('Hora UTC', axis = 1)\n",
    "\n",
    "del clima3_part1\n",
    "del clima3_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clima3.iloc[:,3:21].columns:\n",
    "    \n",
    "    \n",
    "    print(i)\n",
    "    clima3[i] = [float(x.replace(',','.')) if isinstance(x, str) else float(x) for x in clima3[i]]\n",
    "    \n",
    "    \n",
    "# cidade e cep precisamos transformar para string\n",
    "\n",
    "clima3.cidade = clima3.cidade.apply(lambda x: str(x))\n",
    "clima3.cep = clima3.cep.apply(lambda x: str(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Chegando se o tratamento foi efetivo\n",
    "\n",
    "for i in clima3.columns:\n",
    "    print(clima3[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora que todos os valores estão devidamente tratados, vamos reduzir a base para facilitar o trabalho em memória\n",
    "# Vamos reduzir a base a valores diários e não mais horários.\n",
    "\n",
    "# Como o efeito da dengue será visto em dias, não há necessidade a princípio de termos dados de clima de hora em hora\n",
    "# A tentativa será feita em cima de médias diárias\n",
    "\n",
    "\n",
    "clima3_reduzida = clima3.groupby(['DATA (YYYY-MM-DD)','estado','cidade','cep','lat','long']).agg('mean').reset_index()\n",
    "abt3 = pd.merge(clima3_reduzida,dengue_cidades, how = 'inner', left_on = ['DATA (YYYY-MM-DD)','cidade'], right_on = ['DT_NOTIFIC','Nome_Município'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt3.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del clima3\n",
    "del clima3_reduzida\n",
    "del abt3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clima 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora para a base clima 4\n",
    "\n",
    "clima4 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Clima//clima_part4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratando a coluna de Data\n",
    "\n",
    "def ajuste_data(x : str):    \n",
    "    return(x[:4]+'-'+x[5:7]+'-'+x[8:10])\n",
    "\n",
    "# --------------------------------------------------\n",
    "\n",
    "    \n",
    "clima4.Data = clima4.Data.apply(lambda x: ajuste_data(x))\n",
    "clima4 = clima4.rename(columns={'Data': 'DATA (YYYY-MM-DD)'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in clima4.iloc[:,3:21].columns:\n",
    "    \n",
    "    \n",
    "    print(i)\n",
    "    clima4[i] = [float(x.replace(',','.')) if isinstance(x, str) else float(x) for x in clima4[i]]\n",
    "    \n",
    "    \n",
    "# cidade e cep precisamos transformar para string\n",
    "\n",
    "clima4.cidade = clima4.cidade.apply(lambda x: str(x))\n",
    "clima4.cep = clima4.cep.apply(lambda x: str(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chegando se o tratamento foi efetivo\n",
    "\n",
    "for i in clima4.columns:\n",
    "    print(clima4[i].apply(type).value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agora que todos os valores estão devidamente tratados, vamos reduzir a base para facilitar o trabalho em memória\n",
    "# Vamos reduzir a base a valores diários e não mais horários.\n",
    "\n",
    "# Como o efeito da dengue será visto em dias, não há necessidade a princípio de termos dados de clima de hora em hora\n",
    "# A tentativa será feita em cima de médias diárias\n",
    "\n",
    "\n",
    "clima4_reduzida = clima4.groupby(['DATA (YYYY-MM-DD)','estado','cidade','cep','lat','long']).agg('mean').reset_index()\n",
    "abt4 = pd.merge(clima4_reduzida,dengue_cidades, how = 'inner', left_on = ['DATA (YYYY-MM-DD)','cidade'], right_on = ['DT_NOTIFIC','Nome_Município'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt4.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt4.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -----------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizando a ABT empilhando os dados\n",
    "\n",
    "### Até então o que poderíamos tirar de informação das bases foi retirado. O Refinamento da informação será feito no próximo notebook antes da análise exploratória"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt1 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt1.csv')\n",
    "abt2 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt2.csv')\n",
    "abt3 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt3.csv')\n",
    "abt4 = pd.read_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt4.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt_final = pd.concat([abt1,abt2], sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt3 = abt3[['Unnamed: 0', 'DATA (YYYY-MM-DD)', 'estado', 'cidade', 'cep', 'lat',\n",
    "       'long', 'Unnamed: 0.1', 'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)',\n",
    "       'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)',\n",
    "       'PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)',\n",
    "       'PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)',\n",
    "       'RADIACAO GLOBAL (W/m²)',\n",
    "       'TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)',\n",
    "       'TEMPERATURA DO PONTO DE ORVALHO (°C)',\n",
    "       'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)',\n",
    "       'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)',\n",
    "       'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)',\n",
    "       'UMIDADE RELATIVA DO AR, HORARIA (%)',\n",
    "       'VENTO, DIREÇÃO HORARIA (gr) (° (gr))', 'VENTO, RAJADA MAXIMA (m/s)',\n",
    "       'VENTO, VELOCIDADE HORARIA (m/s)', 'Unnamed: 19', 'DT_NOTIFIC',\n",
    "       'ID_MUNICIP', 'NU_ANO', 'Nome_UF', 'Nome_Município', 'NU_NOTIFIC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt4 = abt4[['Unnamed: 0', 'DATA (YYYY-MM-DD)', 'estado', 'cidade', 'cep', 'lat',\n",
    "       'long', 'Unnamed: 0.1', 'PRECIPITAÇÃO TOTAL, HORÁRIO (mm)',\n",
    "       'PRESSAO ATMOSFERICA AO NIVEL DA ESTACAO, HORARIA (mB)',\n",
    "       'PRESSÃO ATMOSFERICA MAX.NA HORA ANT. (AUT) (mB)',\n",
    "       'PRESSÃO ATMOSFERICA MIN. NA HORA ANT. (AUT) (mB)',\n",
    "       'RADIACAO GLOBAL (W/m²)',\n",
    "       'TEMPERATURA DO AR - BULBO SECO, HORARIA (°C)',\n",
    "       'TEMPERATURA DO PONTO DE ORVALHO (°C)',\n",
    "       'TEMPERATURA MÁXIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA MÍNIMA NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MAX. NA HORA ANT. (AUT) (°C)',\n",
    "       'TEMPERATURA ORVALHO MIN. NA HORA ANT. (AUT) (°C)',\n",
    "       'UMIDADE REL. MAX. NA HORA ANT. (AUT) (%)',\n",
    "       'UMIDADE REL. MIN. NA HORA ANT. (AUT) (%)',\n",
    "       'UMIDADE RELATIVA DO AR, HORARIA (%)',\n",
    "       'VENTO, DIREÇÃO HORARIA (gr) (° (gr))', 'VENTO, RAJADA MAXIMA (m/s)',\n",
    "       'VENTO, VELOCIDADE HORARIA (m/s)', 'Unnamed: 19', 'DT_NOTIFIC',\n",
    "       'ID_MUNICIP', 'NU_ANO', 'Nome_UF', 'Nome_Município', 'NU_NOTIFIC']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt_final = pd.concat([abt_final,abt3,abt4], sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abt_final.to_csv(r'E:\\Users\\quadr\\Documents\\MBA\\Trabalhos\\TCC\\Dengue\\Bases\\Bases Tratadas//abt_final.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
